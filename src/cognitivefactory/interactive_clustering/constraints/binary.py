# -*- coding: utf-8 -*-

"""
* Name:         cognitivefactory.interactive_clustering.constraints.binary
* Description:  Implementation of binary constraints manager.
* Author:       Erwan Schild
* Created:      17/03/2021
* Licence:      CeCILL-C License v1.0 (https://cecill.info/licences.fr.html)
"""

# ==============================================================================
# IMPORT PYTHON DEPENDENCIES
# ==============================================================================

from typing import Dict, List, Optional, Set, Tuple  # To type Python code (mypy).

from cognitivefactory.interactive_clustering.constraints.abstract import (  # To use abstract interface.
    AbstractConstraintsManager,
)
from cognitivefactory.interactive_clustering.utils import graph  # To use utilities methods on graph


# ==============================================================================
# BINARY CONSTRAINTS MANAGER
# ==============================================================================
class BinaryConstraintsManager(AbstractConstraintsManager):
    """
    This class implements the binary constraints mangement.
    It inherits from `AbstractConstraintsManager`, and it takes into account the strong transitivity of constraints.

    References:
        - Binary constraints in clustering: `Wagstaff, K. et C. Cardie (2000). Clustering with Instance-level Constraints. Proceedings of the Seventeenth International Conference on Machine Learning, 1103â€“1110.`

    Examples:
        ```python
        # Import.
        from cognitivefactory.interactive_clustering.constraints.binary import BinaryConstraintsManager

        # Create an instance of binary constraints manager.
        constraints_manager = BinaryConstraintsManager(list_of_data_IDs=["0", "1", "2", "3", "4"])

        # Add new data ID.
        constraints_manager.add_data_ID(data_ID="99")

        # Get list of data IDs.
        constraints_manager.get_list_of_managed_data_IDs()

        # Delete an existing data ID.
        constraints_manager.delete_data_ID(data_ID="99")

        # Add constraints.
        constraints_manager.add_constraint(data_ID1="0", data_ID2="1", constraint_type="MUST_LINK")
        constraints_manager.add_constraint(data_ID1="1", data_ID2="2", constraint_type="MUST_LINK")
        constraints_manager.add_constraint(data_ID1="2, data_ID2="3", constraint_type="CANNOT_LINK")

        # Get added constraint.
        constraints_manager.get_added_constraint(data_ID1="0", data_ID2="1")  # expected ("MUST_LINK", 1.0)
        constraints_manager.get_added_constraint(data_ID1="0", data_ID2="2")  # expected None

        # Get inferred constraint.
        constraints_manager.get_inferred_constraint(data_ID1="0", data_ID2="2")  # expected "MUST_LINK"
        constraints_manager.get_inferred_constraint(data_ID1="0", data_ID2="3")  # expected "CANNOT_LINK"
        constraints_manager.get_inferred_constraint(data_ID1="0", data_ID2="4")  # expected None
        ```
    """

    # ==============================================================================
    # INITIALIZATION
    # ==============================================================================
    def __init__(self, list_of_data_IDs: List[str], **kargs) -> None:

        """
        The constructor for Binary Constraints Manager class.
        This class use the strong transitivity to infer on constraints, so constraints values are not taken into account.

        Args:
            list_of_data_IDs (List[str]): The list of data IDs to manage.
            **kargs (dict): Other parameters that can be used in the instantiation.

        Raises:
            ValueError: if `list_of_data_IDs` has duplicates.
        """

        # Define `self._allowed_constraint_types`.
        self._allowed_constraint_types: Set[str] = {
            "MUST_LINK",
            "CANNOT_LINK",
        }
        # Define `self._allowed_constraint_value_range`.
        self._allowed_constraint_value_range: Dict[str, float] = {
            "min": 1.0,
            "max": 1.0,
        }

        # If `list_of_data_IDs` has duplicates, raise `ValueError`.
        if len(list_of_data_IDs) != len(set(list_of_data_IDs)):
            raise ValueError("There is duplicates in `list_of_data_IDs`.")

        # Store `self.kargs` for binary constraints managing.
        self.kargs = kargs

        # Initialize `self._constraints_dictionary`.
        self._constraints_dictionary: Dict[str, Dict[str, Optional[Tuple[str, float]]]] = {
            data_ID1: {
                data_ID2: (
                    ("MUST_LINK", 1.0)
                    if (data_ID1 == data_ID2)
                    else None  # Unknwon constraints if `data_ID1` != `data_ID2`.
                )
                for data_ID2 in list_of_data_IDs
            }
            for data_ID1 in list_of_data_IDs
        }

        # Define `self._constraints_transitivity`.
        self._generate_constraints_transitivity()

    # ==============================================================================
    # DATA_ID MANAGEMENT - ADDITION
    # ==============================================================================
    def add_data_ID(
        self,
        data_ID: str,
    ) -> bool:

        """
        The main method used to add a new data ID to manage.

        Args:
            data_ID (str): The data ID to manage.

        Raises:
            ValueError: if `data_ID` is already managed.

        Returns:
            bool: `True` if the addition is done.
        """

        # If `data_ID` is in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID in self._constraints_dictionary.keys():
            raise ValueError("The `data_ID` `'" + str(data_ID) + "'` is already managed.")

        # Add `data_ID` to `self._constraints_dictionary.keys()`.
        self._constraints_dictionary[data_ID] = {}

        # Define constraint for `data_ID` and all other data IDs.
        for other_data_ID in self._constraints_dictionary.keys():
            self._constraints_dictionary[data_ID][other_data_ID] = (
                ("MUST_LINK", 1.0)
                if (data_ID == other_data_ID)
                else None  # Unknwon constraints if `data_ID` != `other_data_ID`.
            )
            self._constraints_dictionary[other_data_ID][data_ID] = (
                ("MUST_LINK", 1.0)
                if (data_ID == other_data_ID)
                else None  # Unknwon constraints if `data_ID1` != `other_data_ID`.
            )

        # Regenerate `self._constraints_transitivity`.
        # `Equivalent to `self._generate_constraints_transitivity()`
        self._constraints_transitivity[data_ID] = {
            "MUST_LINK": {data_ID: None},
            "CANNOT_LINK": {},
        }

        # Return `True`.
        return True

    # ==============================================================================
    # DATA_ID MANAGEMENT - DELETION
    # ==============================================================================
    def delete_data_ID(
        self,
        data_ID: str,
    ) -> bool:
        """
        The main method used to delete a data ID to no longer manage.

        Args:
            data_ID (str): The data ID to no longer manage.

        Raises:
            ValueError: if `data_ID` is not managed.

        Returns:
            bool: `True` if the deletion is done.
        """

        # If `data_ID` is not in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID not in self._constraints_dictionary.keys():
            raise ValueError("The `data_ID` `'" + str(data_ID) + "'` is not managed.")

        # Remove `data_ID` from `self._constraints_dictionary.keys()`.
        self._constraints_dictionary.pop(data_ID)

        # Remove `data_ID` from all `self._constraints_dictionary[other_data_ID].keys()`.
        for other_data_ID in self._constraints_dictionary.keys():
            self._constraints_dictionary[other_data_ID].pop(data_ID)

        # Regenerate `self._constraints_transitivity`
        self._generate_constraints_transitivity()

        # Return `True`.
        return True

    # ==============================================================================
    # DATA_ID MANAGEMENT - LISTING
    # ==============================================================================
    def get_list_of_managed_data_IDs(
        self,
    ) -> List[str]:
        """
        The main method used to get the list of data IDs that are managed.

        Returns:
            List[str]: The list of data IDs that are managed.
        """

        # Return the possible keys of `self._constraints_dictionary`.
        return list(self._constraints_dictionary.keys())

    # ==============================================================================
    # CONSTRAINTS MANAGEMENT - ADDITION
    # ==============================================================================
    def add_constraint(
        self,
        data_ID1: str,
        data_ID2: str,
        constraint_type: str,
        constraint_value: float = 1.0,
    ) -> bool:
        """
        The main method used to add a constraint between two data IDs.

        Args:
            data_ID1 (str): The first data ID that is concerned for this constraint addition.
            data_ID2 (str): The second data ID that is concerned for this constraint addition.
            constraint_type (str): The type of the constraint to add. The type have to be `"MUST_LINK"` or `"CANNOT_LINK"`.
            constraint_value (float, optional): The value of the constraint to add. The value have to be in range `[0.0, 1.0]`. Defaults to `1.0`.

        Raises:
            ValueError: if `data_ID1`, `data_ID2`, `constraint_type` are not managed, or if a conflict is detected with constraints inference.

        Returns:
            bool: `True` if the addition is done, `False` is the constraint can't be added.
        """

        # If `data_ID1` is not in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID1 not in self._constraints_dictionary.keys():
            raise ValueError("The `data_ID1` `'" + str(data_ID1) + "'` is not managed.")

        # If `data_ID2` is not in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID2 not in self._constraints_dictionary.keys():
            raise ValueError("The `data_ID2` `'" + str(data_ID2) + "'` is not managed.")

        # If the `constraint_type` is not in `self._allowed_constraint_types`, then raises a `ValueError`.
        if constraint_type not in self._allowed_constraint_types:
            raise ValueError(
                "The `constraint_type` `'"
                + str(constraint_type)
                + "'` is not managed. Allowed constraints types are : `"
                + str(self._allowed_constraint_types)
                + "`."
            )

        # Get current added constraint between `data_ID1` and `data_ID2`.
        inferred_constraint: Optional[str] = self.get_inferred_constraint(
            data_ID1=data_ID1,
            data_ID2=data_ID2,
        )

        # Case of conflict with constraints inference.
        if (inferred_constraint is not None) and (inferred_constraint != constraint_type):
            raise ValueError(
                "The `constraint_type` `'"
                + str(constraint_type)
                + "'` is incompatible with the inferred constraint `'"
                + str(inferred_constraint)
                + "'` between data IDs `'"
                + data_ID1
                + "'` and `'"
                + data_ID2
                + "'`."
            )

        # Get current added constraint between `data_ID1` and `data_ID2`.
        added_constraint: Optional[Tuple[str, float]] = self.get_added_constraint(
            data_ID1=data_ID1,
            data_ID2=data_ID2,
        )

        # If the constraint has already be added, ...
        if added_constraint is not None:
            # ... do nothing.
            return True  # `added_constraint[0] == constraint_type`.
        # Otherwise, the constraint has to be added.

        # Add the direct constraint between `data_ID1` and `data_ID2`.
        self._constraints_dictionary[data_ID1][data_ID2] = (constraint_type, 1.0)
        self._constraints_dictionary[data_ID2][data_ID1] = (constraint_type, 1.0)

        # Add the transitivity constraint between `data_ID1` and `data_ID2`.
        self._add_constraint_transitivity(
            data_ID1=data_ID1,
            data_ID2=data_ID2,
            constraint_type=constraint_type,
        )

        return True

    # ==============================================================================
    # CONSTRAINTS MANAGEMENT - DELETION
    # ==============================================================================
    def delete_constraint(
        self,
        data_ID1: str,
        data_ID2: str,
    ) -> bool:
        """
        The main method used to delete a constraint between two data IDs.

        Args:
            data_ID1 (str): The first data ID that is concerned for this constraint deletion.
            data_ID2 (str): The second data ID that is concerned for this constraint deletion.

        Raises:
            ValueError: if `data_ID1` or `data_ID2` are not managed.

        Returns:
            bool: `True` if the deletion is done, `False` if the constraint can't be deleted.
        """

        # If `data_ID1` is not in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID1 not in self._constraints_dictionary.keys():
            raise ValueError("The `data_ID1` `'" + str(data_ID1) + "'` is not managed.")

        # If `data_ID2` is not in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID2 not in self._constraints_dictionary.keys():
            raise ValueError("The `data_ID2` `'" + str(data_ID2) + "'` is not managed.")

        # Delete the constraint between `data_ID1` and `data_ID2`.
        self._constraints_dictionary[data_ID1][data_ID2] = None
        self._constraints_dictionary[data_ID2][data_ID1] = None

        # Regenerate `self._constraints_transitivity`.
        self._generate_constraints_transitivity()

        # Return `True`
        return True

    # ==============================================================================
    # CONSTRAINTS MANAGEMENT - GETTER
    # ==============================================================================
    def get_added_constraint(
        self,
        data_ID1: str,
        data_ID2: str,
    ) -> Optional[Tuple[str, float]]:
        """
        The main method used to get the constraint added between the two data IDs.
        Do not take into account the constraints transitivity, just look at constraints that are explicitly added.

        Args:
            data_ID1 (str): The first data ID that is concerned for this constraint.
            data_ID2 (str): The second data ID that is concerned for this constraint.

        Raises:
            ValueError: if `data_ID1` or `data_ID2` are not managed.

        Returns:
            Optional[Tuple[str, float]]: `None` if no constraint, `(constraint_type, constraint_value)` otherwise.
        """

        # If `data_ID1` is not in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID1 not in self._constraints_dictionary.keys():
            raise ValueError("The `data_ID1` `'" + str(data_ID1) + "'` is not managed.")

        # If `data_ID2` is not in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID2 not in self._constraints_dictionary.keys():
            raise ValueError("The `data_ID2` `'" + str(data_ID2) + "'` is not managed.")

        # Retrun the current added constraint type and value.
        return self._constraints_dictionary[data_ID1][data_ID2]

    # ==============================================================================
    # CONSTRAINTS EXPLORATION - GETTER
    # ==============================================================================
    def get_inferred_constraint(
        self,
        data_ID1: str,
        data_ID2: str,
        threshold: float = 1.0,
    ) -> Optional[str]:
        """
        The main method used to check if the constraint inferred by transitivity between the two data IDs.
        The transitivity is taken into account, and the `threshold` parameter is used to evaluate the impact of constraints transitivity.

        Args:
            data_ID1 (str): The first data ID that is concerned for this constraint.
            data_ID2 (str): The second data ID that is concerned for this constraint.
            threshold (float, optional): The threshold used to evaluate the impact of constraints transitivity link. Defaults to `1.0`.

        Raises:
            ValueError: if `data_ID1`, `data_ID2` or `threshold` are not managed.

        Returns:
            Optional[str]: The type of the inferred constraint. The type can be `None`, `"MUST_LINK"` or `"CANNOT_LINK"`.
        """

        # If `data_ID1` is not in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID1 not in self._constraints_transitivity.keys():
            raise ValueError("The `data_ID1` `'" + str(data_ID1) + "'` is not managed.")

        # If `data_ID2` is not in the data IDs that are currently managed, then raises a `ValueError`.
        if data_ID2 not in self._constraints_transitivity.keys():
            raise ValueError("The `data_ID2` `'" + str(data_ID2) + "'` is not managed.")

        # Case of `"MUST_LINK"`.
        if data_ID1 in self._constraints_transitivity[data_ID2]["MUST_LINK"].keys():
            return "MUST_LINK"

        # Case of `"CANNOT_LINK"`.
        if data_ID1 in self._constraints_transitivity[data_ID2]["CANNOT_LINK"].keys():
            return "CANNOT_LINK"

        # Case of `None`.
        return None

    # ==============================================================================
    # CONSTRAINTS EXPLORATION - LIST OF COMPONENTS GETTER
    # ==============================================================================
    def get_connected_components(
        self,
        threshold: float = 1.0,
    ) -> List[List[str]]:
        """
        The main method used to get the possible lists of data IDs that are linked by a `"MUST_LINK"` constraints.
        Each list forms a component of the constraints transitivity graph, and it forms a partition of the managed data IDs.
        The transitivity is taken into account, and the `threshold` parameters is used if constraints values are used in the constraints transitivity.

        Args:
            threshold (float, optional): The threshold used to define the transitivity link. Defaults to `1.0`.

        Returns:
            List[List[int]]: The list of lists of data IDs that represent a component of the constraints transitivity graph.
        """

        # Initialize the list of connected components.
        list_of_connected_components: List[List[str]] = []

        # For each data ID...
        for data_ID in self._constraints_transitivity.keys():

            # ... get the list of `"MUST_LINK"` data IDs linked by transitivity with `data_ID` ...
            connected_component_of_a_data_ID = list(self._constraints_transitivity[data_ID]["MUST_LINK"].keys())

            # ... and if the connected component is not already get...
            if connected_component_of_a_data_ID not in list_of_connected_components:
                # ... then add it to the list of connected components.
                list_of_connected_components.append(connected_component_of_a_data_ID)

        # Return the list of connected components.
        return list_of_connected_components

    # ==============================================================================
    # CONSTRAINTS EXPLORATION - CHECK COMPLETUDE OF CONSTRAINTS
    # ==============================================================================
    def check_completude_of_constraints(
        self,
        threshold: float = 1.0,
    ) -> bool:
        """
        The main method used to check if all possible constraints are known (not necessarily annotated because of the transitivity).
        The transitivity is taken into account, and the `threshold` parameters is used if constraints values are used in the constraints transitivity.

        Args:
            threshold (float, optional): The threshold used to define the transitivity link. Defaults to `1.0`.

        Returns:
            bool: Return `True` if all constraints are known, `False` otherwise.
        """

        # For each data ID...
        for data_ID in self._constraints_transitivity.keys():

            # ... if some data IDs are not linked by transitivity to this `data_ID` with a `"MUST_LINK"` or `"CANNOT_LINK"` constraints...
            if (
                len(self._constraints_transitivity[data_ID]["MUST_LINK"].keys())
                + len(self._constraints_transitivity[data_ID]["CANNOT_LINK"].keys())
            ) != len(self._constraints_transitivity.keys()):

                # ... then return `False`.
                return False

        # Otherwise, return `True`.
        return True

    # ==============================================================================
    # CONSTRAINTS EXPLORATION - GET MIN AND MAX NUMBER OF CLUSTERS
    # ==============================================================================
    def get_min_and_max_number_of_clusters(
        self,
        threshold: float = 1.0,
    ) -> Tuple[int, int]:
        """
        The main method used to get determine, for a clustering model that would not violate any constraints, the range of the possible clusters number.
        Minimum number of cluster is estimated (lower bound) with the LovÃ sz number of the `"CANNOT_LINK"` constraints complement graph (cf. https://en.wikipedia.org/wiki/Graph_coloring#Lower_bounds_on_the_chromatic_number).
        Maximum number of cluster is defined by the number of `"MUST_LINK"` connected components.
        The transitivity is taken into account, and the `threshold` parameters is used if constraints values are used in the constraints transitivity.

        Args:
            threshold (float, optional): The threshold used to define the transitivity link. Defaults to `1.0`.

        Returns:
            Tuple[int,int]: The minimum and the maximum possible clusters numbers (for a clustering model that would not violate any constraints).
        """
        # Determine the lower bound of minimum clusters number with the LovÃ sz numberof the `"CANNOT_LINK"` constraints graph.
        # The lower bound has to be greater than 2.
        lower_bound_of_minimum_clusters_number: int = max(
            2,
            int(  # Get the integer part of the lower bound
                round(  # Round at 5 decimal if the lower bound if close to the next interger (i.e. 2.99999 -> 3.0)
                    graph.compute_lovasz_theta_number(
                        # Get the number of data IDs as number of vertex.
                        number_of_vertex=len(self._constraints_transitivity.keys()),
                        # Get the complement of the `"CANNOT_LINK"` graph.
                        list_of_egdes=[
                            (i1, i2)
                            for i1, data_ID1 in enumerate(self._constraints_transitivity.keys())
                            for i2, data_ID2 in enumerate(self._constraints_transitivity.keys())
                            if (i1 < i2)
                            and (  # To get the complement, get all possible link that are not a `"CANNOT_LINK"`.
                                data_ID2 not in self._constraints_transitivity[data_ID1]["CANNOT_LINK"].keys()
                            )
                        ],
                    )["theta"],
                    5,
                )
            ),
        )

        # Determine the maximum clusters number with the number of `"MUST_LINK"` connected components.
        maximum_clusters_number: int = len(self.get_connected_components())

        # Return minimum and maximum.
        return (lower_bound_of_minimum_clusters_number, maximum_clusters_number)

    # ==============================================================================
    # CONSTRAINTS TRANSITIVITY MANAGEMENT - GENERATE CONSTRAINTS TRANSITIVITY GRAPH
    # ==============================================================================
    def _generate_constraints_transitivity(
        self,
    ) -> None:
        """
        Generate `self._constraints_transitivity`, a constraints dictionary that takes into account the transitivity of constraints.
        Suppose there is no inconsistency in `self._constraints_dictionary`.
        It uses `Dict[str, None]` to simulate ordered sets.
        """

        self._constraints_transitivity: Dict[str, Dict[str, Dict[str, None]]] = {
            data_ID: {
                "MUST_LINK": {data_ID: None},  # Initialize MUST_LINK clusters constraints.
                "CANNOT_LINK": {},  # Initialize CANNOT_LINK clusters constraints.
            }
            for data_ID in self._constraints_dictionary.keys()
        }

        for data_ID1 in self._constraints_transitivity.keys():
            for data_ID2 in self._constraints_transitivity.keys():

                # Optimization : `self._constraints_dictionary` is symetric, so one pass is enough.
                if data_ID1 > data_ID2:
                    continue

                # Get the constraint between `data_ID1` and `data_ID2`.
                constraint = self._constraints_dictionary[data_ID1][data_ID2]

                # Add the constraint transitivity if the constraint is not `None`.
                if constraint is not None:
                    self._add_constraint_transitivity(
                        data_ID1=data_ID1,
                        data_ID2=data_ID2,
                        constraint_type=constraint[0],
                    )

    # ==============================================================================
    # CONSTRAINTS TRANSITIVITY MANAGEMENT - ADD CONSTRAINT TRANSITIVITY
    # ==============================================================================
    def _add_constraint_transitivity(
        self,
        data_ID1: str,
        data_ID2: str,
        constraint_type: str,
    ) -> bool:
        """
        Add constraint transitivity in `self._constraints_transitivity` between `data_ID1` and `data_ID2` for constraint type `constraint_type`.
        Suppose there is no inconsistency in `self._constraints_dictionary`.

        Args:
            data_ID1 (str): The first data ID that is concerned for this constraint transitivity addition.
            data_ID2 (str): The second data ID that is concerned for this constraint transitivity addition.
            constraint_type (str): The type of the constraint to add. The type have to be `"MUST_LINK"` or `"CANNOT_LINK"`.

        Returns:
            bool: `True` when the transitivity addition is done.
        """

        ###
        ### Case 1 : `constraint_type` is `"MUST_LINK"`.
        ###
        if constraint_type == "MUST_LINK":

            # Define new common set of `"MUST_LINK"` data IDs,
            # by merging the sets of `"MUST_LINK"` data IDs for `data_ID1` and `data_ID2`.
            new_MUST_LINK_common_set: Dict[str, None] = {
                **self._constraints_transitivity[data_ID1]["MUST_LINK"],
                **self._constraints_transitivity[data_ID2]["MUST_LINK"],
            }

            # Define new common set of `"CANNOT_LINK"` data IDs,
            # by merging the sets of `"CANNOT_LINK"` data IDs for `data_ID1` and `data_ID2`.
            new_CANNOT_LINK_common_set: Dict[str, None] = {
                **self._constraints_transitivity[data_ID1]["CANNOT_LINK"],
                **self._constraints_transitivity[data_ID2]["CANNOT_LINK"],
            }

            # For each data that are now similar to `data_ID1` and `data_ID2`...
            for data_ID_ML in new_MUST_LINK_common_set.keys():
                # ... affect the new set of `"MUST_LINK"` constraints...
                self._constraints_transitivity[data_ID_ML]["MUST_LINK"] = new_MUST_LINK_common_set
                # ... and affect the new set of `"CANNOT_LINK"` constraints.
                self._constraints_transitivity[data_ID_ML]["CANNOT_LINK"] = new_CANNOT_LINK_common_set

            # For each data that are now different to `data_ID1` and `data_ID2`...
            for data_ID_CL in new_CANNOT_LINK_common_set.keys():
                # ... affect the new set of `"CANNOT_LINK"` constraints.
                self._constraints_transitivity[data_ID_CL]["CANNOT_LINK"] = {
                    **self._constraints_transitivity[data_ID_CL]["CANNOT_LINK"],
                    **new_MUST_LINK_common_set,
                }

        ###
        ### Case 2 : `constraint_type` is `"CANNOT_LINK"`.
        ###
        else:  # if constraint_type == "CANNOT_LINK":

            # Define new common set of `"CANNOT_LINK"` data IDs for data IDs that are similar to `data_ID1`.
            new_CANNOT_LINK_set_for_data_ID1: Dict[str, None] = {
                **self._constraints_transitivity[data_ID1]["CANNOT_LINK"],
                **self._constraints_transitivity[data_ID2]["MUST_LINK"],
            }

            # Define new common set of `"CANNOT_LINK"` data IDs for data IDs that are similar to `data_ID2`.
            new_CANNOT_LINK_set_for_data_ID2: Dict[str, None] = {
                **self._constraints_transitivity[data_ID2]["CANNOT_LINK"],
                **self._constraints_transitivity[data_ID1]["MUST_LINK"],
            }

            # For each data that are similar to `data_ID1`...
            for data_ID_like_data_ID1 in self._constraints_transitivity[data_ID1]["MUST_LINK"].keys():
                # ... affect the new list of `"CANNOT_LINK"` constraints.
                self._constraints_transitivity[data_ID_like_data_ID1]["CANNOT_LINK"] = new_CANNOT_LINK_set_for_data_ID1

            # For each data that are similar to `data_ID2`...
            for data_ID_like_data_ID2 in self._constraints_transitivity[data_ID2]["MUST_LINK"].keys():
                # ... affect the new list of `"CANNOT_LINK"` constraints.
                self._constraints_transitivity[data_ID_like_data_ID2]["CANNOT_LINK"] = new_CANNOT_LINK_set_for_data_ID2

        # Return `True`
        return True
